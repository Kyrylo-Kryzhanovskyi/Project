import json
import os
import re
from typing import List
import torch
from transformers import pipeline

# –ù–æ–≤—ñ –º—ñ—Ç–∫–∏ (—Ç—ñ–ª—å–∫–∏ —Ç–æ–∫—Å–∏—á–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó, –±–µ–∑ Safe)
LABELS = [
    "Hate speech or harassment",
    "Propaganda or ideological harm",
    "Exploitation or abuse",
    "Self-harm or suicide"
]

class TextClassifier:
    def __init__(self,
                 model_name="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",  # –ö—Ä–∞—â–∞ –º–æ–¥–µ–ª—å –¥–ª—è NLI
                 device = 0 if torch.cuda.is_available() else -1,  # 0 –¥–ª—è GPU
                 threshold=0.5,  # –ó–º–µ–Ω—à–µ–Ω–∏–π –ø–æ—Ä—ñ–≥ –¥–ª—è —á—É—Ç–ª–∏–≤–æ—Å—Ç—ñ
                 batch_size=8):
        
        self.pipeline = pipeline(
            "zero-shot-classification",
            model=model_name,
            device=device,
            hypothesis_template="This message contains {}."  # –Ø–≤–Ω–∏–π —à–∞–±–ª–æ–Ω
        )
        self.threshold = threshold
        self.batch_size = batch_size
        self.cache = {}
        self.cache_path = "classification_cache.json"

        if os.path.exists(self.cache_path):
            try:
                with open(self.cache_path, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–µ—à: {e}")

    def classify(self, texts: List[str]) -> List[dict]:
        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—ñ–≤
        original_texts = []
        for t in texts:
            if not t or not t.strip():
                continue
            clean_t = t.strip()
            low_t = clean_t.lower()
            if low_t in ["[media]", "[photo]", "[video]"]:
                continue
            if len(clean_t) < 3 or clean_t.isdigit():
                continue
            if re.fullmatch(r'(.)\1{2,}', clean_t):
                continue
            original_texts.append(clean_t)

        if not original_texts:
            print("‚ùå –ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –ø—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó.")
            return []

        results = [None] * len(original_texts)
        to_classify_texts = []
        to_classify_indices = {}
        cached_count = 0

        for idx, text in enumerate(original_texts):
            if text in self.cache:
                cached = self.cache[text]
                results[idx] = {"text": text, "labels": cached["labels"], "scores": cached["scores"]}
                cached_count += 1
            else:
                if text not in to_classify_indices:
                    to_classify_indices[text] = []
                    to_classify_texts.append(text)
                to_classify_indices[text].append(idx)

        if to_classify_texts:
            try:
                from tqdm import tqdm
            except ImportError:
                tqdm = None

            if tqdm:
                pbar = tqdm(total=len(original_texts), desc="üß† –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è", unit="msg")
                pbar.update(cached_count)

            for i in range(0, len(to_classify_texts), self.batch_size):
                batch_texts = to_classify_texts[i:i + self.batch_size]
                batch_results = self.pipeline(
                    batch_texts,
                    candidate_labels=LABELS,
                    multi_label=True
                )

                if not isinstance(batch_results, list):
                    batch_results = [batch_results]

                for txt, result in zip(batch_texts, batch_results):
                    filtered_labels = []
                    filtered_scores = []

                    for label, score in zip(result["labels"], result["scores"]):
                        if score >= self.threshold:
                            filtered_labels.append(label)
                            filtered_scores.append(score)

                    # –Ø–∫—â–æ –∂–æ–¥–Ω–∞ —Ç–æ–∫—Å–∏—á–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ ‚Äî –≤–≤–∞–∂–∞—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –±–µ–∑–ø–µ—á–Ω–∏–º
                    if not filtered_labels:
                        filtered_labels = ["Safe"]
                        filtered_scores = [1.0]

                    for idx in to_classify_indices.get(txt, []):
                        results[idx] = {"text": txt, "labels": filtered_labels, "scores": filtered_scores}
                    self.cache[txt] = {"labels": filtered_labels, "scores": filtered_scores}

                if tqdm:
                    pbar.update(len(batch_texts))

            if tqdm:
                pbar.close()

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à
        try:
            with open(self.cache_path, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∫–µ—à—É: {e}")

        return results
